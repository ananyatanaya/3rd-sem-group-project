{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Namespace' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4979fe135f91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Generate random bounding box bounding_box_color for each label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Namespace' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import sys\n",
    "import cv2\n",
    "from math import pow, sqrt\n",
    "\n",
    "\n",
    "# Parse the arguments from command line\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-v', '--video', type = str, default = '', help = 'Video file path. If no path is given, video is captured using device.')\n",
    "\n",
    "parser.add_argument('-m', '--model', default = 'SSD_MobileNet.caffemodel', help = \"Path to the pretrained model.\")\n",
    "    \n",
    "parser.add_argument('-p', '--prototxt', default = 'SSD_MobileNet_prototxt.txt', help = 'Prototxt of the model.')\n",
    "\n",
    "parser.add_argument('-l', '--labels', default = 'class_labels.txt', help = 'Labels of the dataset.')\n",
    "\n",
    "parser.add_argument('-c', '--confidence', type = float, default = 0.2, help='Set confidence for detecting objects')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "labels = [line.strip() for line in open(args['labels'])]\n",
    "\n",
    "# Generate random bounding box bounding_box_color for each label\n",
    "bounding_box_color = np.random.uniform(0, 255, size=(len(labels), 3))\n",
    "\n",
    "\n",
    "# Load model\n",
    "print(\"\\nLoading model...\\n\")\n",
    "network = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])\n",
    "\n",
    "print(\"\\nStreaming video using device...\\n\")\n",
    "\n",
    "\n",
    "# Capture video from file or through device\n",
    "if args['video']:\n",
    "    cap = cv2.VideoCapture(args['video'])\n",
    "else:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "frame_no = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    frame_no = frame_no+1\n",
    "\n",
    "    # Capture one frame after another\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    (h, w) = frame.shape[:2]\n",
    "\n",
    "    # Resize the frame to suite the model requirements. Resize the frame to 300X300 pixels\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "\n",
    "    network.setInput(blob)\n",
    "    detections = network.forward()\n",
    "\n",
    "    pos_dict = dict()\n",
    "    coordinates = dict()\n",
    "\n",
    "    # Focal length\n",
    "    F = 615\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence > args[\"confidence\"]:\n",
    "\n",
    "            class_id = int(detections[0, 0, i, 1])\n",
    "\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype('int')\n",
    "\n",
    "            # Filtering only persons detected in the frame. Class Id of 'person' is 15\n",
    "            if class_id == 15.00:\n",
    "\n",
    "                # Draw bounding box for the object\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY), bounding_box_color[class_id], 2)\n",
    "\n",
    "                label = \"{}: {:.2f}%\".format(labels[class_id], confidence * 100)\n",
    "                print(\"{}\".format(label))\n",
    "\n",
    "\n",
    "                coordinates[i] = (startX, startY, endX, endY)\n",
    "\n",
    "                # Mid point of bounding box\n",
    "                x_mid = round((startX+endX)/2,4)\n",
    "                y_mid = round((startY+endY)/2,4)\n",
    "\n",
    "                height = round(endY-startY,4)\n",
    "\n",
    "                # Distance from camera based on triangle similarity\n",
    "                distance = (165 * F)/height\n",
    "                print(\"Distance(cm):{dist}\\n\".format(dist=distance))\n",
    "\n",
    "                # Mid-point of bounding boxes (in cm) based on triangle similarity technique\n",
    "                x_mid_cm = (x_mid * distance) / F\n",
    "                y_mid_cm = (y_mid * distance) / F\n",
    "                pos_dict[i] = (x_mid_cm,y_mid_cm,distance)\n",
    "\n",
    "    # Distance between every object detected in a frame\n",
    "    close_objects = set()\n",
    "    for i in pos_dict.keys():\n",
    "        for j in pos_dict.keys():\n",
    "            if i < j:\n",
    "                dist = sqrt(pow(pos_dict[i][0]-pos_dict[j][0],2) + pow(pos_dict[i][1]-pos_dict[j][1],2) + pow(pos_dict[i][2]-pos_dict[j][2],2))\n",
    "\n",
    "                # Check if distance less than 2 metres or 200 centimetres\n",
    "                if dist < 200:\n",
    "                    close_objects.add(i)\n",
    "                    close_objects.add(j)\n",
    "\n",
    "    for i in pos_dict.keys():\n",
    "        if i in close_objects:\n",
    "            COLOR = np.array([0,0,255])\n",
    "        else:\n",
    "            COLOR = np.array([0,255,0])\n",
    "        (startX, startY, endX, endY) = coordinates[i]\n",
    "\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), COLOR, 2)\n",
    "        y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "        # Convert cms to feet\n",
    "        cv2.putText(frame, 'Depth: {i} ft'.format(i=round(pos_dict[i][2]/30.48,4)), (startX, y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR, 2)\n",
    "\n",
    "    cv2.namedWindow('Frame',cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.resizeWindow('Frame',800,600)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Press `q` to exit\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Clean\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
